{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://zhuanlan.zhihu.com/p/32445437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:28:15.620151Z",
     "start_time": "2018-04-08T13:28:15.602614Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:28:29.979608Z",
     "start_time": "2018-04-08T13:28:29.885331Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv.gz\")\n",
    "test = pd.read_csv(\"test.csv.gz\")\n",
    "combined = pd.concat([train,test],axis =0, ignore_index =True)\n",
    "ntrain = train.shape[0]\n",
    "Y_train = train[\"SalePrice\"]\n",
    "X_train = train.drop([\"Id\",\"SalePrice\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:29:25.859482Z",
     "start_time": "2018-04-08T13:29:25.846576Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "SKIPMAP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:29:22.474186Z",
     "start_time": "2018-04-08T13:29:22.403102Z"
    }
   },
   "outputs": [],
   "source": [
    "def eda_plot(df=combined[0:ntrain],cols=[],target=Y_train):\n",
    "    #Usage: eda_plot(df,cols=[],target=\"\"):\n",
    "    # df: the dataframe\n",
    "    # cols: the feature columns want to explorate\n",
    "    # target the target columns want to refer\n",
    "    if SKIPMAP == False:\n",
    "        plt.close(\"all\") #clear all plt figure in buffers\n",
    "        ax_nth =len(cols)\n",
    "        \n",
    "        if ax_nth ==0:\n",
    "            print(\"No features need print\\n\")\n",
    "        elif ax_nth ==1:\n",
    "            fig,ax =plt.subplots(2,ax_nth,figsize=(ax_nth*4,5),sharex=True)\n",
    "\n",
    "            for i in range(ax_nth):\n",
    "                col=cols[i]\n",
    "                data = df[col]\n",
    "                #data = data[data.notnull()]\n",
    "                \n",
    "                if (data.dtype == np.number):\n",
    "                    sns.distplot(data[data.notnull()], ax=ax[0],rug=True)\n",
    "                    sns.regplot(data,target,ax=ax[1])               \n",
    "\n",
    "                elif data.dtype is np.object:\n",
    "                    sns.countplot(data[data.notnull()],ax=ax[0])\n",
    "                    sns.pointplot(x=train[col],y=target,ax=ax[1]);\n",
    "                else:\n",
    "                    print(data.dtype)\n",
    "        else:\n",
    "            fig,ax =plt.subplots(2,ax_nth,figsize=(ax_nth*4,5))\n",
    "\n",
    "            for i in range(ax_nth):\n",
    "                col=cols[i]\n",
    "                data = df[col]\n",
    "\n",
    "                if (data.dtype == np.number):\n",
    "                    sns.distplot(data[data.notnull()], ax=ax[0,i],rug=True)\n",
    "                    sns.regplot(data,target,ax=ax[1,i])\n",
    "                    #ax[1,i].set_title(col)\n",
    "\n",
    "                elif data.dtype== np.object:\n",
    "                    sns.countplot(data[data.notnull()],ax=ax[0,i])\n",
    "                    sns.pointplot(x=train[col],y=target,ax=ax[1,i]);\n",
    "                    #ax[1,i].set_title(col)\n",
    "\n",
    "        plt.subplots_adjust(hspace=0.1,wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:29:39.586063Z",
     "start_time": "2018-04-08T13:29:39.547961Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainvstest():\n",
    "    from scipy.stats import ks_2samp\n",
    "    tab_combined=pd.concat([train,test],axis=0,keys=[\"train\",\"test\"],names=[\"sets\"])\n",
    "    tmp_data = tab_combined.head().reset_index(level=0)\n",
    "    num_cols = tmp_data.select_dtypes(include=[\"number\"]).columns\n",
    "    num_cols = num_cols.drop([\"Id\", \"SalePrice\"])\n",
    "    total_num_cols = len(num_cols[:5])\n",
    "\n",
    "    for col in num_cols:\n",
    "        v_ks,p_ks=ks_2samp(train[col],test[col])\n",
    "        if p_ks<0.2:\n",
    "            print(\"KS: {0:,.2f}\\t Pvalue {1:.2f}\\t {2}\".format(v_ks,p_ks,col))\n",
    "            fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
    "            stats.probplot(np.log1p(train[col]),plot=ax[0])\n",
    "            ax[0].set_title(\"Train__\"+col)\n",
    "            stats.probplot(np.log1p(test[col]),plot=ax[1])\n",
    "            ax[1].set_title(\"Test__\"+col)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:29:54.944266Z",
     "start_time": "2018-04-08T13:29:54.927245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_col_compress(col, threshold=0.005):\n",
    "    #copy the code from stackoverflow\n",
    "    # removes the bind\n",
    "    dummy_col=col.copy()\n",
    "\n",
    "    # what is the ratio of a dummy in whole column\n",
    "    count = pd.value_counts(dummy_col) / len(dummy_col)\n",
    "\n",
    "    # cond whether the ratios is higher than the threshold\n",
    "    mask = dummy_col.isin(count[count > threshold].index)\n",
    "\n",
    "    # replace the ones which ratio is lower than the threshold by a special name\n",
    "    dummy_col[~mask] = \"dum_others\"\n",
    "\n",
    "    return dummy_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:30:10.303875Z",
     "start_time": "2018-04-08T13:30:06.785038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAE9CAYAAAC86S8MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMsZ43v8H4lAl40My30YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2f7744940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eda_plot(cols=[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:31:01.910824Z",
     "start_time": "2018-04-08T13:31:01.633825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features is bad/missing value? The answer is: 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff2f63bff98>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAD4CAYAAACqnDJ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2f6546128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_missing_value = combined.isnull().sum()/combined.shape[0]\n",
    "cols_missing_value = cols_missing_value[cols_missing_value>0]\n",
    "print(\"How many features is bad/missing value? The answer is:\",cols_missing_value.shape[0])\n",
    "cols_missing_value.sort_values(ascending=False).head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:31:23.948555Z",
     "start_time": "2018-04-08T13:31:23.941978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_start(df):\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:31:35.292998Z",
     "start_time": "2018-04-08T13:31:35.270353Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_missing_remove(pre_combined):\n",
    "    \n",
    "    missing_cols = pre_combined.drop([\"Id\",\"SalePrice\"],axis=1).isnull().sum()\n",
    "    remove_cols = missing_cols[missing_cols>(pre_combined.shape[0]*0.4)].index.tolist()\n",
    "    pre_combined = pre_combined.drop(remove_cols,axis=1)\n",
    "    \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:31:47.728532Z",
     "start_time": "2018-04-08T13:31:47.705165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_basic_fillna(df=combined):\n",
    "    local_ntrain = ntrain\n",
    "    pre_combined=df.copy()\n",
    "    \n",
    "    #print(\"The input train dimension:\\t\", pre_combined[0:ntrain].shape)\n",
    "    #print(\"The input test dimension:\\t\", pre_combined[ntrain:].drop(\"SalePrice\",axis=1).shape)\n",
    "    \n",
    "    num_cols = pre_combined.drop([\"Id\",\"SalePrice\"],axis=1).select_dtypes(include=[np.number]).columns\n",
    "    cat_cols = pre_combined.select_dtypes(include=[np.object]).columns\n",
    "    \n",
    "\n",
    "    pre_combined[num_cols]= pre_combined[num_cols].fillna(pre_combined[num_cols].median())\n",
    "    # Median is my favoraite fillna mode, which can eliminate the skew impact.\n",
    "    pre_combined[cat_cols]= pre_combined[cat_cols].fillna(\"NA\")\n",
    "    pre_combined= pd.concat([pre_combined[[\"Id\",\"SalePrice\"]],pre_combined[cat_cols],pre_combined[num_cols]],axis=1)\n",
    "    return pre_combined  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:31:59.168995Z",
     "start_time": "2018-04-08T13:31:59.138639Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_basic_fillna_lotfrontage(df=combined):\n",
    "    local_ntrain = ntrain\n",
    "    pre_combined=df.copy()\n",
    "    \n",
    "    # below lotfrontage code was inspired by PhilipBallJourney to the top 10%\n",
    "    # sourcd code https://www.kaggle.com/fiorenza2/journey-to-the-top-10\n",
    "    \n",
    "    gb_neigh_LF = pre_combined['LotFrontage'].groupby(pre_combined['Neighborhood'])\n",
    "    \n",
    "    for key,group in gb_neigh_LF:\n",
    "        # find where we are both simultaneously missing values and where the key exists\n",
    "        lot_f_nulls_nei = pre_combined['LotFrontage'].isnull() & (pre_combined['Neighborhood'] == key)\n",
    "        # fill in those blanks with the median of the key's group object\n",
    "        pre_combined.loc[lot_f_nulls_nei,'LotFrontage'] = group.median()\n",
    "\n",
    "    \n",
    "    \n",
    "    num_cols = pre_combined.drop([\"Id\",\"SalePrice\"],axis=1).select_dtypes(include=[np.number]).columns\n",
    "     \n",
    "    cat_cols = pre_combined.select_dtypes(include=[np.object]).columns\n",
    "    \n",
    "    \n",
    "    pre_combined[num_cols]= pre_combined[num_cols].fillna(pre_combined[num_cols].median())\n",
    "    # Median is my favoraite fillna mode, which can eliminate the skew impact.\n",
    "    #pre_combined[cat_cols]= pre_combined[cat_cols].fillna(\"NA\")\n",
    "    \n",
    "    pre_combined= pd.concat([pre_combined[[\"Id\",\"SalePrice\"]],pre_combined[cat_cols],pre_combined[num_cols]],axis=1)\n",
    "    return pre_combined  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:32:10.319007Z",
     "start_time": "2018-04-08T13:32:10.286254Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_basic_lotfrontage_ratio(df=combined):\n",
    "    local_ntrain = ntrain\n",
    "    pre_combined=df.copy()\n",
    "\n",
    "    #Lotfrontage fill mssing value\n",
    "    pre_combined[\"lotfrontage_ratio\"] = pre_combined[\"LotArea\"]/pre_combined[\"LotFrontage\"]\n",
    "    pre_combined[\"lotfrontage_ratio\"] = pre_combined.groupby([\"LotShape\",\"LotConfig\"])[\"lotfrontage_ratio\"].transform(lambda x: x.fillna(x.median()))\n",
    "    pre_combined[\"LotFrontage\"] = pre_combined[\"LotFrontage\"].fillna(pre_combined[\"LotArea\"]/pre_combined[\"lotfrontage_ratio\"])\n",
    "    pre_combined=pre_combined.drop(\"lotfrontage_ratio\",axis=1)\n",
    "\n",
    "    num_cols = pre_combined.drop([\"Id\",\"SalePrice\"],axis=1).select_dtypes(include=[np.number]).columns\n",
    "     \n",
    "    cat_cols = pre_combined.select_dtypes(include=[np.object]).columns\n",
    "    \n",
    "    pre_combined[num_cols]= pre_combined[num_cols].fillna(pre_combined[num_cols].median())\n",
    "    # Median is my favoraite fillna mode, which can eliminate the skew impact.\n",
    "    pre_combined[cat_cols]= pre_combined[cat_cols].fillna(\"NA\")\n",
    "    pre_combined= pd.concat([pre_combined[[\"Id\",\"SalePrice\"]],pre_combined[cat_cols],pre_combined[num_cols]],axis=1)\n",
    "    return pre_combined  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:32:28.437523Z",
     "start_time": "2018-04-08T13:32:28.254181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_manual_fillna(df=combined):\n",
    "    from datetime import datetime\n",
    "    local_ntrain = train.shape[0]\n",
    "    pre_combined=df.copy()\n",
    "    \n",
    "    #print(\"The input train dimension:\\t\", pre_combined[0:ntrain].shape)\n",
    "    #print(\"The input testdimension:\\t\", pre_combined[ntrain:].drop(\"SalePrice\",axis=1).shape)\n",
    "    cols_Qual_Cond_Class=[\"MSSubClass\"]\n",
    "    pre_combined[cols_Qual_Cond_Class] = pre_combined[cols_Qual_Cond_Class].astype(np.str)\n",
    "    \n",
    "    # convert orinal feature as interger and fillna \n",
    "    cols_ordinal = [\"HeatingQC\",\"KitchenQual\",\"ExterQual\",\\\n",
    "                    \"ExterCond\",\"FireplaceQu\",\"GarageQual\",\\\n",
    "                    \"GarageCond\",\"BsmtCond\",\"BsmtQual\"]\n",
    "  \n",
    "    qal_map = {\"Ex\":5, #Excellent\n",
    "               \"Gd\":4, #Good\n",
    "               \"TA\":3, #Average/Typical \n",
    "               \"Fa\":2, #Fair\n",
    "               \"Po\":1, #Poor\n",
    "               \"NA\":0 # no \n",
    "              }\n",
    "    pre_combined[cols_ordinal]=pre_combined[cols_ordinal].fillna(\"NA\") \n",
    "    pre_combined[cols_ordinal]=pre_combined[cols_ordinal].replace(qal_map)\n",
    "    pre_combined[cols_ordinal]=pre_combined[cols_ordinal].astype(np.int)\n",
    "  \n",
    "    #convert basement finish type to ordinal info\n",
    "    cols_BsmtFinTypeMap = [\"BsmtFinType1\",\"BsmtFinType2\"]          \n",
    "    BsmtFinTypeMap ={\"GLQ\":6,  #Good Living Quarters\n",
    "             \"ALQ\":5,  #Average Living Quarters\n",
    "             \"BLQ\":4,  #Below Average Living Quarters\n",
    "             \"Rec\":3,  #Average Rec Room\n",
    "             \"LwQ\":2,  #Low Quality\n",
    "             \"Unf\":1,  #unfinshed\n",
    "             \"NA\":0,   #No Basement\n",
    "            }\n",
    "\n",
    "    pre_combined[cols_BsmtFinTypeMap]=pre_combined[cols_BsmtFinTypeMap].fillna(\"NA\") \n",
    "    pre_combined[cols_BsmtFinTypeMap]=pre_combined[cols_BsmtFinTypeMap].replace(BsmtFinTypeMap)\n",
    "    \n",
    "    FenceMap ={\"GdPrv\":4, #Good Privacy\n",
    "               \"MnPrv\":3, #Minimum Privacy\n",
    "               \"GdWo\":2,#Good Wood\n",
    "               \"MnWw\":1,#Minimum Wood/Wire\n",
    "               \"NA\":0,#No Fence\n",
    "              }\n",
    "    pre_combined[\"Fence\"]=pre_combined[\"Fence\"].fillna(\"NA\") \n",
    "    pre_combined[\"Fence\"]=pre_combined[\"Fence\"].replace(FenceMap)\n",
    "    \n",
    "    #Lotfrontage fill mssing value\n",
    "    pre_combined[\"lotfrontage_ratio\"] = pre_combined[\"LotArea\"]/pre_combined[\"LotFrontage\"]\n",
    "    pre_combined[\"lotfrontage_ratio\"] = pre_combined.groupby([\"LotShape\",\"LotConfig\"])[\"lotfrontage_ratio\"].transform(lambda x: x.fillna(x.median()))\n",
    "    pre_combined[\"LotFrontage\"] = pre_combined[\"LotFrontage\"].fillna(pre_combined[\"LotArea\"]/pre_combined[\"lotfrontage_ratio\"])\n",
    "    pre_combined=pre_combined.drop(\"lotfrontage_ratio\",axis=1)\n",
    "    \n",
    "    #fill missing value to misc features\n",
    "    cols_mis = [\"MiscFeature\",\"Alley\"]\n",
    "    pre_combined[cols_mis] = pre_combined[cols_mis].fillna(\"NA\")  # assuming most of house has no such misc feature, so fillNA with NA.\n",
    "    pre_combined[cols_mis] = pre_combined[cols_mis].astype(np.str)\n",
    "    \n",
    "    \n",
    "    #fill missing value to Garage related features\n",
    "    #Assuming no garage for thos missing value\n",
    "    cols_garage = [\"GarageType\",\"GarageFinish\"]\n",
    "    pre_combined[cols_garage]= pre_combined[cols_garage].fillna(\"NA\")       \n",
    "    pre_combined[\"GarageCars\"] =pre_combined[\"GarageCars\"].fillna(pre_combined[\"GarageCars\"].median()).astype(int)\n",
    "    pre_combined[\"GarageArea\"] =pre_combined[\"GarageArea\"].fillna(pre_combined[\"GarageArea\"].median()).astype(int)\n",
    "    \n",
    "    #fill missing value to Basement related features\n",
    "    mask = pre_combined[\"TotalBsmtSF\"].isnull()\n",
    "    \n",
    "    pre_combined[\"TotalBsmtSF\"]=  pre_combined[\"TotalBsmtSF\"].fillna(0)\n",
    "\n",
    "    mask = (pre_combined[\"BsmtCond\"].isnull().any()) and (pre_combined[\"TotalBsmtSF\"] <= 0)\n",
    "    pre_combined[[\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\"]]= pre_combined[[\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\"]].fillna(0)\n",
    "\n",
    "    cols_bsmt = [\"BsmtExposure\"]\n",
    "    BsmtExposureMAP ={\"Gd\":4, #Good Exposure\n",
    "                      \"Av\":3, #Average Exposure (split levels or foyers typically score average or above)\n",
    "                      \"Mn\":2, #Mimimum Exposure\n",
    "                      \"No\":1, #No Exposure\n",
    "                      \"NA\":0, #No Basement\n",
    "                     }\n",
    "    pre_combined[cols_bsmt] =pre_combined[cols_bsmt].fillna(\"NA\")    \n",
    "    pre_combined[cols_bsmt]=pre_combined[cols_bsmt].replace(FenceMap)\n",
    "\n",
    "    cols_Bsmt_Bath = [\"BsmtHalfBath\",\"BsmtFullBath\"]\n",
    "    pre_combined[cols_Bsmt_Bath] =pre_combined[cols_Bsmt_Bath].fillna(pre_combined[cols_Bsmt_Bath].median())\n",
    "\n",
    "    #fill missing value to MasVnr and Exterior related features\n",
    "    cols_exterior =[\"MasVnrType\",\"MasVnrArea\",\"Exterior1st\",\"Exterior2nd\"]\n",
    "    mask = pre_combined[\"MasVnrType\"].isnull()\n",
    "    #pre_combined.loc[mask,cols_exterior]\n",
    "    pre_combined[\"MasVnrType\"] = pre_combined[\"MasVnrType\"].fillna(\"None\")\n",
    "    pre_combined[\"MasVnrArea\"] = pre_combined[\"MasVnrArea\"].fillna(0)\n",
    "    pre_combined[\"Exterior1st\"] = pre_combined[\"Exterior1st\"].fillna(\"Other\")\n",
    "    pre_combined[\"Exterior2nd\"] = pre_combined[\"Exterior2nd\"].fillna(\"Other\")\n",
    "    pre_combined.isnull().sum().sort_values(ascending=False).head(10)\n",
    "    \n",
    "\n",
    "    # fill missing value for MSZoning\n",
    "    cols_Zone =[\"MSSubClass\",\"MSZoning\",\"Neighborhood\"]\n",
    "\n",
    "    mask = pre_combined[\"Neighborhood\"].str.contains(\"Mitchel\")\n",
    "    pre_combined[\"MSZoning\"] = pre_combined.loc[mask,[\"MSZoning\"]].fillna(\"C (all)\") #fill the common value of similar localtion\n",
    "    mask = pre_combined[\"Neighborhood\"].str.contains(\"IDOTRR\")\n",
    "    pre_combined[\"MSZoning\"] = pre_combined[\"MSZoning\"].fillna(\"C (all)\") #fill the common value of similar localtion\n",
    "    \n",
    "    pre_combined[\"Electrical\"] =pre_combined[\"Electrical\"].fillna(\"Mix\")\n",
    "    pre_combined[\"Utilities\"] = pre_combined[\"Utilities\"].fillna(\"ELO\")\n",
    "    pre_combined[\"Functional\"] = pre_combined[\"Functional\"].fillna(\"NA\")\n",
    "    pre_combined[\"SaleType\"] = pre_combined[\"SaleType\"].fillna(\"Oth\")\n",
    "    pre_combined[\"PoolQC\"] = pre_combined[\"PoolQC\"].fillna(\"NA\")\n",
    "    \n",
    "    cols_mis = [\"MiscFeature\",\"Alley\",\"Fence\"]\n",
    "    pre_combined[cols_mis] = pre_combined[cols_mis].fillna(\"NA\")  # assuming most of house has no such misc feature, so fillNA with NA.\n",
    "    pre_combined[cols_mis]=pre_combined[cols_mis].astype(np.str)\n",
    "    \n",
    "    #solve Year related feature missing value\n",
    "    cols_time = [\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"MoSold\",\"YrSold\"]\n",
    "    pre_combined[\"GarageYrBlt\"] = pre_combined[\"GarageYrBlt\"].fillna(pre_combined[\"YearBuilt\"]) #use building year for garage even no garage.\n",
    "       \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:32:48.712718Z",
     "start_time": "2018-04-08T13:32:48.413619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_fillna_ascat(pre_combined):\n",
    "    from datetime import datetime\n",
    "    \n",
    "    local_ntrain = pre_combined.SalePrice.notnull().sum()\n",
    "\n",
    "    #convert quality feature to category type \n",
    "    #def feature group with same categories value\n",
    "    cols_Subclass = [\"MSSubClass\"]\n",
    "    cols_Zone = [\"MSZoning\"]\n",
    "    cols_Overall =[\"OverallQual\",\"OverallCond\"]\n",
    "    \n",
    "    cols_Qual = [\"BsmtCond\",\"BsmtQual\",\\\n",
    "                 \"ExterQual\",\"ExterCond\",\\\n",
    "                 \"FireplaceQu\",\"GarageQual\",\"GarageCond\",\\\n",
    "                 \"HeatingQC\",\"KitchenQual\",\n",
    "                \"PoolQC\"]\n",
    "    cols_BsmtFinType = [\"BsmtFinType1\",\"BsmtFinType2\"]\n",
    "    cols_access = [\"Alley\",\"Street\"]\n",
    "    cols_condition = [\"Condition1\",\"Condition2\"]\n",
    "    cols_fence =[\"Fence\"]\n",
    "    cols_exposure = [\"BsmtExposure\"]\n",
    "    cols_miscfeat = [\"MiscFeature\"]\n",
    "    cols_exter = [\"Exterior1st\",\"Exterior2nd\"]\n",
    "    cols_MasVnr =[\"MasVnrType\"]\n",
    "    cols_GarageType = [\"GarageType\"]\n",
    "    cols_GarageFinish =[\"GarageFinish\"]\n",
    "    cols_Functional = [\"Functional\"]\n",
    "    cols_Util =[\"Utilities\"]\n",
    "    cols_SaleType = [\"SaleType\"]\n",
    "    cols_Electrical = [\"Electrical\"]\n",
    "  \n",
    "  \n",
    "    #define the map of categories valus group\n",
    "    cat_Subclass = [\"20\",#1-STORY 1946 & NEWER ALL STYLES\n",
    "                    \"30\",#1-STORY 1945 & OLDER\n",
    "                    \"40\",#1-STORY W/FINISHED ATTIC ALL AGES\n",
    "                    \"45\",#1-1/2 STORY - UNFINISHED ALL AGES\n",
    "                    \"50\",#1-1/2 STORY FINISHED ALL AGES\n",
    "                    \"60\",#2-STORY 1946 & NEWER\n",
    "                    \"70\",#2-STORY 1945 & OLDER\n",
    "                    \"75\",#2-1/2 STORY ALL AGES\n",
    "                    \"80\",#SPLIT OR MULTI-LEVEL\n",
    "                    \"85\",#SPLIT FOYER\n",
    "                    \"90\",#DUPLEX - ALL STYLES AND AGES\n",
    "                    \"120\",#1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "                    \"150\",#1-1/2 STORY PUD - ALL AGES\n",
    "                    \"160\",#2-STORY PUD - 1946 & NEWER\n",
    "                    \"180\",#PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "                    \"190\",#2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "                   ]\n",
    "    cat_Zone = [\"A\",#Agriculture\n",
    "                \"C (all)\",#Commercial #the train/test value is different than the data_description file.\n",
    "                \"FV\",#Floating Village Residential\n",
    "                \"I\",#Industrial\n",
    "                \"RH\",#Residential High Density\n",
    "                \"RL\",#Residential Low Density\n",
    "                \"RP\",#Residential Low Density Park \n",
    "                \"RM\",#Residential Medium Density\n",
    "               ]\n",
    "    cat_Overall = [\"10\",\"9\",\"8\",\"7\",\"6\",\"5\",\"4\",\"3\",\"2\",\"1\"]\n",
    "    cat_Qual = [\"Ex\",\"Gd\",\"TA\",\"Fa\",\"Po\",\"NA\"]\n",
    "    cat_BsmtFinType = [\"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NA\"]\n",
    "    cat_access = [\"Grvl\",\"Pave\",\"NA\"]\n",
    "    cat_conditions= [\"Artery\",\"Feedr\",\"Norm\",\"RRNn\",\"RRAn\",\"PosN\",\"PosA\",\"RRNe\",\"RRAe\"]\n",
    "    cat_fence = [\"GdPrv\",#Good Privacy\n",
    "                \"MnPrv\",#Minimum Privacy\n",
    "                \"GdWo\",#Good Wood\n",
    "                \"MnWw\",#Minimum Wood/Wire\n",
    "                \"NA\",#No Fence\n",
    "                ]\n",
    "    cat_exposure = [\"Gd\", #Good Exposure\n",
    "                    \"Av\", #Average Exposure (split levels or foyers typically score average or above)\n",
    "                    \"Mn\", #Mimimum Exposure\n",
    "                    \"No\", #No Exposure\n",
    "                    \"NA\", #No Basement\n",
    "                   ]\n",
    "    cat_miscfeat = [\"Elev\",#Elevator\n",
    "                    \"Gar2\",#2nd Garage (if not described in garage section)\n",
    "                    \"Othr\",#Other\n",
    "                    \"Shed\",#Shed (over 100 SF)\n",
    "                    \"TenC\",#Tennis Court\n",
    "                    \"NA\",#None\n",
    "                   ]\n",
    "    cat_exter =[\"AsbShng\",#Asbestos Shingles\n",
    "                \"AsphShn\",#Asphalt Shingles\n",
    "                \"BrkComm\",#Brick Common Brk Cmn BrkComm\n",
    "                \"BrkFace\",#Brick Face\n",
    "                \"CBlock\",#Cinder Block\n",
    "                \"CementBd\",#Cement Board #CementBd was the  data_description value\n",
    "                \"HdBoard\",#Hard Board\n",
    "                \"ImStucc\",#Imitation Stucco\n",
    "                \"MetalSd\",#Metal Siding\n",
    "                \"Other\",#Other\n",
    "                \"Plywood\",#Plywood\n",
    "                \"PreCast\",#PreCast,#\n",
    "                \"Stone\",#Stone\n",
    "                \"Stucco\",#Stucco\n",
    "                \"VinylSd\",#Vinyl Siding\n",
    "                \"Wd Sdng\",#Wood Siding\n",
    "                \"WdShing\",#Wood Shingles #Wd Shng WdShing\n",
    "                    ]\n",
    "    cat_MasVnr =[\"BrkCmn\",#Brick Common\n",
    "                \"BrkFace\",#Brick Face\n",
    "                \"CBlock\",#Cinder Block\n",
    "                \"None\",#None\n",
    "                \"Stone\",#Stone\n",
    "                ]\n",
    "    cat_GarageType =[\"2Types\",#More than one type of garage\n",
    "                    \"Attchd\",#Attached to home\n",
    "                    \"Basment\",#Basement Garage\n",
    "                    \"BuiltIn\",#Built-In (Garage part of house - typically has room above garage)\n",
    "                    \"CarPort\",#Car Port\n",
    "                    \"Detchd\",#Detached from home\n",
    "                    \"NA\",#No Garage\n",
    "                    ]\n",
    "    cat_GarageFinish =[\"Fin\",#Finished\n",
    "                        \"RFn\",#Rough Finished,#\n",
    "                        \"Unf\",#Unfinished\n",
    "                        \"NA\",#No Garage\n",
    "                      ]\n",
    "    cat_Functional = [\"Typ\",#Typical Functionality\n",
    "                    \"Min1\",#Minor Deductions 1\n",
    "                    \"Min2\",#Minor Deductions 2\n",
    "                    \"Mod\",#Moderate Deductions\n",
    "                    \"Maj1\",#Major Deductions 1\n",
    "                    \"Maj2\",#Major Deductions 2\n",
    "                    \"Sev\",#Severely Damaged\n",
    "                    \"Sal\",#Salvage only\n",
    "                    ]\n",
    "    cat_Util =[\"AllPub\",#All public Utilities (E,G,W,& S)\n",
    "               \"NoSewr\",#Electricity, Gas, and Water (Septic Tank)\n",
    "                \"NoSeWa\",#Electricity and Gas Only\n",
    "                \"ELO\",#Electricity only,#\n",
    "                ]\n",
    "    cat_SaleType =[\"WD\",#Warranty Deed - Conventional\n",
    "                   \"CWD\",#Warranty Deed - Cash\n",
    "                    \"VWD\",#Warranty Deed - VA Loan\n",
    "                    \"New\",#Home just constructed and sold\n",
    "                    \"COD\",#Court Officer Deed/Estate\n",
    "                    \"Con\",#Contract 15% Down payment regular terms\n",
    "                    \"ConLw\",#Contract Low Down payment and low interest\n",
    "                    \"ConLI\",#Contract Low Interest\n",
    "                    \"ConLD\",#Contract Low Down\n",
    "                    \"Oth\",#Other\n",
    "                    ]\n",
    "    cat_Electrical = [\"SBrkr\",#Standard Circuit Breakers & Romex\n",
    "                        \"FuseA\",#Fuse Box over 60 AMP and all Romex wiring (Average),#\n",
    "                        \"FuseF\",#60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "                        \"FuseP\",#60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "                        \"Mix\",#Mixed\n",
    "                        ]\n",
    "    \n",
    "    \n",
    "    ###########################################################################\n",
    "    #define the collection of group features &categories value by diction type\n",
    "    Dict_category={\"Qual\":[cols_Qual,cat_Qual,\"NA\",\"Ordinal\"],\n",
    "                   \"Overall\":[cols_Overall,cat_Overall,\"5\",\"Ordinal\"], # It is integer already. no need overwork\n",
    "                   \"BsmtFinType\":[cols_BsmtFinType,cat_BsmtFinType,\"NA\",\"Ordinal\"],\n",
    "                   \"Access\":[cols_access,cat_access,\"NA\",\"Ordinal\"],\n",
    "                    \"Fence\":[cols_fence,cat_fence,\"NA\",\"Ordinal\"],\n",
    "                   \"Exposure\":[cols_exposure,cat_exposure,\"NA\",\"v\"],\n",
    "                   \"GarageFinish\":[cols_GarageFinish,cat_GarageFinish,\"NA\",\"Ordinal\"],\n",
    "                   \"Functional\":[cols_Functional,cat_Functional,\"Typ\",\"Ordinal\"], #fill na with lowest quality\n",
    "                   \"Utility\":[cols_Util,cat_Util,\"ELO\",\"Ordinal\"], # fillNA with lowest quality\n",
    "            \n",
    "                   \"Subclass\":[cols_Subclass,cat_Subclass,\"NA\",\"Nominal\"],\n",
    "                   \"Zone\":[cols_Zone,cat_Zone,\"RL\",\"Nominal\"], #RL is most popular zone value. \"C(all) is the study result\"\n",
    "                   \"Cond\":[cols_condition,cat_conditions,\"Norm\",\"Nominal\"],\n",
    "                   \"MiscFeature\":[cols_miscfeat,cat_miscfeat,\"NA\",\"Nominal\"],\n",
    "                   \"Exter\":[cols_exter,cat_exter,\"Other\",\"Nominal\"],\n",
    "                   \"MasVnr\":[cols_MasVnr,cat_MasVnr,\"None\",\"Nominal\"],\n",
    "                   \"GarageType\":[cols_GarageType,cat_GarageType,\"NA\",\"Nominal\"],\n",
    "                   \"SaleType\":[cols_SaleType, cat_SaleType,\"WD\",\"Nominal\"],\n",
    "                   \"Electrical\":[cols_Electrical,cat_Electrical,\"SBrkr\",\"Nominal\"],\n",
    "                   }\n",
    "    \n",
    "   \n",
    "    #Change input feature type to string, especailly to below integer type  \n",
    "    pre_combined[cols_Overall] = pre_combined[cols_Overall].astype(str)\n",
    "    pre_combined[cols_Subclass] = pre_combined[cols_Subclass].astype(str)\n",
    "    \n",
    "    \n",
    "    #fix the raw data mistyping\n",
    "    exter_map = {\"Brk Cmn\":\"BrkComm\", \n",
    "                 \"CmentBd\":\"CementBd\",\n",
    "                 \"CemntBd\":\"CementBd\",\n",
    "                 \"Wd Shng\":\"WdShing\" }\n",
    "    pre_combined[cols_exter]=pre_combined[cols_exter].replace(exter_map)\n",
    "   \n",
    "    for v in Dict_category.values():\n",
    "        cols_cat = v[0]\n",
    "        cat_order =v[1]\n",
    "        cat_fillnavalue=v[2]\n",
    "        for col in cols_cat:\n",
    "            if col in pre_combined.columns:\n",
    "                pre_combined[col]=pre_combined[col].fillna(cat_fillnavalue) \n",
    "                #if not isOrdinal:\n",
    "                if v[3] ==\"Nominal\":\n",
    "                    pre_combined[col]=pre_combined[col].astype('category',ordered =True,categories=cat_order)\n",
    "                elif v[3]==\"Ordinal\":\n",
    "                    pre_combined[col]=pre_combined[col].astype('category',ordered =True,categories=cat_order).cat.codes\n",
    "                    pre_combined[col] = pre_combined[col].astype(np.number)\n",
    "            \n",
    "\n",
    "                \n",
    "    \n",
    "    #pre_combined[cols_Overall] = pre_combined[cols_Overall].fillna(pre_combined[cols_Overall].median())\n",
    "    \n",
    "    #Lotfrontage fill mssing value\n",
    "    \n",
    "    pre_combined[\"LotFrontage\"] = pre_combined.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "  \n",
    "    \n",
    "    #fill missing value to Garage related features\n",
    "    #Assuming no garage for thos missing value\n",
    "    pre_combined[\"GarageCars\"] =pre_combined[\"GarageCars\"].fillna(0).astype(int)\n",
    "    pre_combined[\"GarageArea\"] =pre_combined[\"GarageArea\"].fillna(0).astype(int)\n",
    "    \n",
    "    #fill missing value to Basement related features\n",
    "    pre_combined[[\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\"]]= pre_combined[[\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\"]].fillna(0)\n",
    "    pre_combined[\"TotalBsmtSF\"]= pre_combined[\"BsmtFinSF1\"] + pre_combined[\"BsmtFinSF2\"]+pre_combined[\"BsmtUnfSF\"]\n",
    "    \n",
    "    cols_Bsmt_Bath = [\"BsmtHalfBath\",\"BsmtFullBath\"]\n",
    "    pre_combined[cols_Bsmt_Bath] =pre_combined[cols_Bsmt_Bath].fillna(0) #assuming mean\n",
    "\n",
    "    pre_combined[\"MasVnrArea\"] = pre_combined[\"MasVnrArea\"].fillna(0) #filled per study\n",
    "      \n",
    "    #solve Year related feature missing value\n",
    "    #cols_time = [\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"MoSold\",\"YrSold\"]\n",
    "    pre_combined[\"GarageYrBlt\"] = pre_combined[\"GarageYrBlt\"].fillna(pre_combined[\"YearBuilt\"]) #use building year for garage even no garage.\n",
    "\n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:32:56.719021Z",
     "start_time": "2018-04-08T13:32:56.705908Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_drop_cols(pre_combined):\n",
    "    pre_combied = pre_combined.drop(['Street', 'Utilities', 'Condition2', 'RoofMatl', 'Heating'], axis = 1)\n",
    "    \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:33:07.704460Z",
     "start_time": "2018-04-08T13:33:07.678027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_extract( pre_combined):\n",
    "    \n",
    "    #extract 3 age feature(building, Garage, and remodel)\n",
    "    pre_combined[\"BldAge\"] = pre_combined[\"YrSold\"] - pre_combined[\"YearBuilt\"]\n",
    "    pre_combined[\"GarageAge\"] = pre_combined[\"YrSold\"] - pre_combined[\"GarageYrBlt\"]\n",
    "    pre_combined[\"RemodelAge\"] = pre_combined[\"YrSold\"] - pre_combined[\"YearRemodAdd\"]\n",
    "    SoldYM_df = pd.DataFrame({\"year\":pre_combined.YrSold,\"month\":pre_combined.MoSold.astype(\"int\").astype(\"object\"),\"day\":1})\n",
    "    SoldYM_df = pd.to_datetime(SoldYM_df,format='%Y%m%d',unit=\"D\")\n",
    "    pre_combined[\"SoldYM\"]=SoldYM_df.apply(lambda x: x.toordinal())\n",
    "    \n",
    "    #extract total space features\n",
    "    # three options for calculating the total Square feet. (Garage & basement has very high sknew, remove them )\n",
    "    #pre_combined[\"TotalSQF\"] = pre_combined[\"GarageArea\"] + pre_combined['TotalBsmtSF']  +pre_combined[\"GrLivArea\"]+pre_combined['1stFlrSF'] + pre_combined['2ndFlrSF']  \n",
    "    #pre_combined[\"TotalSQF\"] = pre_combined['TotalBsmtSF'] + pre_combined['1stFlrSF'] + pre_combined['2ndFlrSF'] \n",
    "    pre_combined[\"No2ndFlr\"] =pre_combined[\"2ndFlrSF\"] ==0\n",
    "    \n",
    "    pre_combined[\"TotalSQF\"] = pre_combined['1stFlrSF'] + pre_combined['2ndFlrSF'] +pre_combined[\"GrLivArea\"]\n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:33:19.085468Z",
     "start_time": "2018-04-08T13:33:19.062321Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_extract_2ndflr( pre_combined):\n",
    "    \n",
    "    #extract 3 age feature(building, Garage, and remodel)\n",
    "    pre_combined[\"BldAge\"] = pre_combined[\"YrSold\"] - pre_combined[\"YearBuilt\"]\n",
    "    pre_combined[\"GarageAge\"] = pre_combined[\"YrSold\"] - pre_combined[\"GarageYrBlt\"]\n",
    "    pre_combined[\"RemodelAge\"] = pre_combined[\"YrSold\"] - pre_combined[\"YearRemodAdd\"]\n",
    "    SoldYM_df = pd.DataFrame({\"year\":pre_combined.YrSold,\"month\":pre_combined.MoSold.astype(\"int\").astype(\"object\"),\"day\":1})\n",
    "    SoldYM_df = pd.to_datetime(SoldYM_df,format='%Y%m%d',unit=\"D\")\n",
    "    pre_combined[\"SoldYM\"]=SoldYM_df.apply(lambda x: x.toordinal())\n",
    "    \n",
    "    #extract total space features\n",
    "    # three options for calculating the total Square feet. (Garage & basement has very high sknew, remove them )\n",
    "    #pre_combined[\"TotalSQF\"] = pre_combined[\"GarageArea\"] + pre_combined['TotalBsmtSF']  +pre_combined[\"GrLivArea\"]+pre_combined['1stFlrSF'] + pre_combined['2ndFlrSF']  \n",
    "    #pre_combined[\"TotalSQF\"] = pre_combined['TotalBsmtSF'] + pre_combined['1stFlrSF'] + pre_combined['2ndFlrSF'] \n",
    "    pre_combined[\"No2ndFlr\"] =(pre_combined[\"2ndFlrSF\"] ==0).astype(int) # transfer true /false to 1/0\n",
    "    \n",
    "    \n",
    "    pre_combined[\"TotalSQF\"] = pre_combined['1stFlrSF'] + pre_combined['2ndFlrSF'] +pre_combined[\"GrLivArea\"]\n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:33:26.970011Z",
     "start_time": "2018-04-08T13:33:26.954645Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_outliers4k(pre_combined):\n",
    "    \n",
    "    mask = (pre_combined[\"GrLivArea\"] >3500 ) & (pre_combined[\"SalePrice\"] <300000)\n",
    "    index_outliers = pre_combined[mask].index\n",
    "    print(index_outliers)\n",
    "    pre_combined = pre_combined.drop(index_outliers,axis=0)\n",
    "    \n",
    "    return (pre_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:33:39.886151Z",
     "start_time": "2018-04-08T13:33:39.858678Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_outliersdrop(pre_combined,ratio =0.002):\n",
    "    # note, it could done by statsmodel as well. it will explored in future\n",
    "    ratio =1-ratio\n",
    "    global ntrain\n",
    "    ntrain = pre_combined[\"SalePrice\"].notnull().sum()\n",
    "   \n",
    "    Y_train = pre_combined[\"SalePrice\"][:ntrain]\n",
    "\n",
    "    num_cols = pre_combined.select_dtypes(include=[np.number]).columns\n",
    "    out_df = pre_combined[0:ntrain][num_cols]\n",
    "    \n",
    "    top5 = np.abs(out_df.corrwith(Y_train)).sort_values(ascending=False)[:5]\n",
    "\n",
    "    #eda_plot(df=pre_combined[:ntrain],cols=top5.index)\n",
    "    limit = out_df[\"GrLivArea\"].quantile(ratio)\n",
    " \n",
    "    # limit use to remove the outliers\n",
    "    #dropindex = out_df[(out_df[\"GrLivArea\"]>4000) & (out_df[\"SalePrice\"]<30000)].index\n",
    "    dropindex = out_df[out_df[\"GrLivArea\"]>limit].index\n",
    "    print(\"dropped index :\",dropindex)\n",
    "    dropped_pre_combined =pre_combined.drop(dropindex)\n",
    "    #*****************************\n",
    "    dropped_Y_train = Y_train.drop(dropindex)\n",
    "    ntrain =dropped_Y_train.shape[0]\n",
    "    #*****************************\n",
    "    print(\"\\n\\n*****Drop outlier based on ratio > {0:.3f} quantile :\".format(ratio))\n",
    "    #print(\"New shape of collected data\",dropped_pre_combined.shape)\n",
    "    return dropped_pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:33:48.984442Z",
     "start_time": "2018-04-08T13:33:48.969592Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_drop4cols(pre_combined): \n",
    "    cols_drop =['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']\n",
    "    # the 4 features(columns was identified earlier which missing data >50%)\n",
    "    #pre_combined, ntrain = customize_fillna_extract_outliersdrop()\n",
    "    #pre_combined = customize_fillna_extract_outliersdrop()\n",
    "    for col in cols_drop:\n",
    "        if col in pre_combined.columns:\n",
    "            pre_combined = pre_combined.drop(col,axis=1)\n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:34:01.127279Z",
     "start_time": "2018-04-08T13:34:01.089406Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_unitprice(pre_combined,unit_price_cols=[\"ind_price_feet_bld\",\"ind_price_feet_lot\"] ):\n",
    "    #revision add log1p to remove the skew\n",
    "    \n",
    "    if unit_price_cols == [\"ind_price_feet_bld\",\"ind_price_feet_lot\"]:\n",
    "        pre_combined[\"ind_price_feet_bld\"] = pre_combined[\"SalePrice\"]/pre_combined[\"TotalSQF\"]\n",
    "        pre_combined[\"ind_price_feet_lot\"] = pre_combined[\"SalePrice\"]/pre_combined[\"LotArea\"]\n",
    "    elif unit_price_cols == [\"ind_price_feet_bld\"]:\n",
    "         pre_combined[\"ind_price_feet_bld\"] = pre_combined[\"SalePrice\"]/pre_combined[\"TotalSQF\"]\n",
    "            \n",
    "    elif unit_price_cols == [\"ind_price_feet_lot\"]:\n",
    "        pre_combined[\"ind_price_feet_lot\"] = pre_combined[\"SalePrice\"]/pre_combined[\"LotArea\"]\n",
    "        \n",
    "    else:\n",
    "        return pre_combined\n",
    "    \n",
    "    #fill_mean = lambda g: g.fillna(g.mean()) \n",
    "    #unit_price_cols=[\"ind_price_feet_bld\",\"ind_price_feet_lot\"] \n",
    "    \n",
    "    #for col in unit_price_cols: pre_combined[col] = np.nan #initialize the unit_price cols\n",
    "    \n",
    "    grouper0 = [\"Neighborhood\",\"YrSold\",\"MoSold\"] \n",
    "    grouper1 = [\"Neighborhood\",\"YrSold\"] \n",
    "    grouper2 = [\"Neighborhood\",\"MoSold\"] \n",
    "    grouper3 = [\"Neighborhood\"] \n",
    "    groupers={#\"g0\":grouper0,\"g1\":grouper1,\"g2\":grouper2,\n",
    "              \"g3\":grouper3,}\n",
    "    \n",
    "    for grouper in groupers.values():\n",
    "    #level 0 fill, mean unit  price based on place\n",
    "        grp_fill_values= pre_combined.groupby(by=grouper)[unit_price_cols].transform(np.median) #change to median from mena to avoid outliers impact\n",
    "        if grouper == [\"Neighborhood\",\"YrSold\",\"MoSold\"]:\n",
    "            pre_combined[unit_price_cols] = grp_fill_values\n",
    "        else:\n",
    "            pre_combined[unit_price_cols]= pre_combined[unit_price_cols].fillna(grp_fill_values)\n",
    "    \n",
    "    #in case of any unit price sample still missing value. fill it with all data median value\n",
    "    pre_combined[unit_price_cols] =pre_combined[unit_price_cols].fillna(pre_combined[unit_price_cols].median())\n",
    "    \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:34:11.731437Z",
     "start_time": "2018-04-08T13:34:11.704636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_log_getdummies(pre_combined,skew_ratio=0.75,cat_ratio=0):\n",
    "    from scipy.stats import skew\n",
    "    skew_limit =skew_ratio #I got this limit from Kaggle directly. Someone use 1 , someone use 0.75. I just use 0.75 by random and has no detail study yet\n",
    "    cat_threshold = cat_ratio\n",
    "\n",
    "  \n",
    "    num_cols = pre_combined.select_dtypes(include=[np.number]).columns\n",
    "    cat_cols = pre_combined.select_dtypes(include=[np.object]).columns\n",
    "    \n",
    "    #log transform skewed numeric features:\n",
    "    skewed_Series = np.abs(pre_combined[num_cols].skew()) #compute skewness\n",
    "    skewed_cols = skewed_Series[skewed_Series > skew_limit].index.values\n",
    "    \n",
    "    pre_combined[skewed_cols] = np.log1p(pre_combined[skewed_cols])\n",
    "    skewed_Series = abs(pre_combined.skew()) #compute skewness\n",
    "    skewed_cols = skewed_Series[skewed_Series > skew_limit].index.tolist()\n",
    "\n",
    "  \n",
    "       \n",
    "    for col in cat_cols:\n",
    "        pre_combined[col]=cat_col_compress(pre_combined[col],threshold=cat_threshold) # threshold set to zero as it get high core for all estimatior  except ridge based\n",
    "     \n",
    "    pre_combined= pd.get_dummies(pre_combined,drop_first=True)\n",
    " \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:34:22.973531Z",
     "start_time": "2018-04-08T13:34:22.937119Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_boxcox_getdummies(pre_combined,skew_ratio=1,cat_ratio=0):\n",
    "    from scipy.stats import boxcox\n",
    "    from scipy.special import boxcox1p\n",
    "    skew_limit =skew_ratio #I got this limit from Kaggle directly. Someone use 1 , someone use 0.75. I just use 0.75 by random and has no detail study yet\n",
    "    cat_threshold = cat_ratio\n",
    "\n",
    "  \n",
    "    num_cols = pre_combined.select_dtypes(include=[np.number]).columns\n",
    "    cat_cols = pre_combined.select_dtypes(include=[np.object]).columns\n",
    "    \n",
    "    #log transform skewed numeric features:\n",
    "    skewed_Series = np.abs(pre_combined[num_cols].skew()) #compute skewness\n",
    "    skewed_cols = skewed_Series[skewed_Series > skew_limit].index.values\n",
    "    print(skew_cols)\n",
    "    pre_combined[skewed_cols],_= boxcox1p(pre_combined[skewed_cols])\n",
    "    skewed_Series = abs(pre_combined.skew()) #compute skewness\n",
    "    skewed_cols = skewed_Series[skewed_Series > skew_limit].index.tolist()\n",
    "        \n",
    "    for col in cat_cols:\n",
    "        pre_combined[col]=cat_col_compress(pre_combined[col],threshold=cat_threshold) # threshold set to zero as it get high core for all estimatior  except ridge based\n",
    "     \n",
    "    pre_combined= pd.get_dummies(pre_combined,drop_first=True)\n",
    " \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:34:30.030356Z",
     "start_time": "2018-04-08T13:34:30.021412Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_bypass(df,arg1=None,arg2=None):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:34:38.625119Z",
     "start_time": "2018-04-08T13:34:38.611313Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_drop_dummycols(pre_combined):\n",
    "    cols = [\"MSSubClass_160\",\"MSZoning_C (all)\"]\n",
    "    pre_combined=pre_combined.drop(cols,axis=1)\n",
    "    \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:34:48.347286Z",
     "start_time": "2018-04-08T13:34:48.314183Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_PcaIca_cols(pre_combined,target_col=\"SalePrice\",n_pca=10,SEED=42):\n",
    "    from sklearn.decomposition import PCA, FastICA\n",
    "    n_comp = n_pca\n",
    "    \n",
    "    global ntrain \n",
    "    \n",
    "    X_train = pre_combined[:ntrain].drop([target_col],axis=1)\n",
    "    X_test = pre_combined[ntrain:].drop([target_col],axis=1)\n",
    "    Y_train = pre_combined[:ntrain][target_col]\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_comp, random_state=SEED)\n",
    "    pca2_results = pca.fit_transform(pre_combined.drop([target_col],axis=1))\n",
    "  \n",
    "    # ICA\n",
    "    ica = FastICA(n_components=n_comp, random_state=SEED)\n",
    "    ica2_results = ica.fit_transform(pre_combined.drop([target_col],axis=1))\n",
    "\n",
    "    # Append decomposition components to datasets\n",
    "    for i in range(1, n_comp+1):\n",
    "        pre_combined['pca_' + str(i)] = pca2_results[:,i-1]\n",
    "        pre_combined['ica_' + str(i)] = ica2_results[:,i-1]\n",
    "    \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:35:00.317516Z",
     "start_time": "2018-04-08T13:35:00.242955Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_kmean_col(pre_combined,target_col=\"SalePrice\", kmean_col=\"GrLivArea\",n_cluster=10,SEED=42):\n",
    "    \"\"\"\n",
    "    df,target_col=\"\",n_cluster=4, col=\"X0\",SEED=42\n",
    "    \"\"\"\n",
    "    from xgboost import XGBRegressor,XGBClassifier\n",
    "\n",
    "    #from lightgbm import LGBMRegressor,LGBMClassifier\n",
    "    from sklearn.cluster import KMeans\n",
    "    col = kmean_col\n",
    "    \n",
    "    global ntrain \n",
    "    \n",
    "    X_train = pre_combined[:ntrain].drop([target_col,\"Id\"],axis=1)\n",
    "    X_test = pre_combined[ntrain:].drop([target_col,\"Id\"],axis=1)\n",
    "    Y_train = pre_combined[:ntrain][target_col]\n",
    "    \n",
    "    class cluster_target_encoder:\n",
    "    \n",
    "        def make_encoding(self,df):\n",
    "            self.encoding = df.groupby('X')['y'].mean()\n",
    "            \n",
    "        def fit(self,X,y):\n",
    "            df = pd.DataFrame(columns=['X','y'],index=X.index)\n",
    "            df['X'] = X\n",
    "            df['y'] = y\n",
    "            self.make_encoding(df)\n",
    "            \n",
    "            clust = KMeans(n_cluster,random_state=SEED)\n",
    "            \n",
    "            labels = clust.fit_predict(self.encoding[df['X'].values].values.reshape(-1,1))\n",
    "            df['labels'] = labels\n",
    "            self.clust_encoding = df.groupby('X')['labels'].median()\n",
    "\n",
    "        def transform(self,X):\n",
    "            res = X.map(self.clust_encoding).astype(float)\n",
    "            return res\n",
    "\n",
    "        def fit_transform(self,X,y):\n",
    "            self.fit(X,y)\n",
    "            return self.transform(X)\n",
    "        \n",
    "    enc1 = cluster_target_encoder()\n",
    "    \n",
    "    #fit & transform\n",
    "    labels_train = enc1.fit_transform(X_train[col],Y_train)\n",
    "    labels_test =  enc1.transform(X_test[col])\n",
    "\n",
    "    #fill na of label_test\n",
    "    \n",
    "    est = XGBClassifier()\n",
    "    est.fit(X_train.select_dtypes(include=[np.number]),labels_train)\n",
    "    pred_labels_test = est.predict(X_test.select_dtypes(include=[np.number]))[np.isnan(labels_test)]\n",
    "    labels_test[np.isnan(labels_test)]  = est.predict(\n",
    "    X_test.select_dtypes(include=[np.number]))[np.isnan(labels_test)]  \n",
    "    \n",
    "    labels_train.name =\"Glv_K\"\n",
    "    pre_combined = pd.concat([pre_combined,labels_train],axis=1)\n",
    "    pre_combined.Glv_K = pre_combined.Glv_K.fillna(labels_test).astype(\"str\")\n",
    "    #print(pre_combined.shape)\n",
    "    #pre_combined = pd.get_dummies(pre_combined,columns=[\"Glv_K\"],drop_first=True)\n",
    "    #print(pre_combined.shape)\n",
    "    return pre_combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:35:11.364535Z",
     "start_time": "2018-04-08T13:35:11.329949Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_export(pre_output,name=\"\"):\n",
    "    \n",
    "    if (pre_output is None) :\n",
    "        print(\"None input! Expect pre_combined dataframe name as parameter\")\n",
    "        return\n",
    "    elif pre_output.drop(\"SalePrice\",axis=1).isnull().sum().sum()>0:\n",
    "        print(\"Dataframe still missing value! pls check again\")\n",
    "        return\n",
    "    elif name ==\"\" :\n",
    "        print(\"Expect preparing option name to generate output file\")\n",
    "        print(\"The out file name will be [Preparing_Output_<name>_20171029.h5] \")\n",
    "        return\n",
    "    else:\n",
    "        from datetime import datetime\n",
    "        savetime=datetime.now().strftime(\"%m-%d-%H_%M\")\n",
    "        directory_name = \"./prepare/\"\n",
    "        filename = directory_name + name +\"_\"+ savetime +\".h5\"\n",
    "        local_ntrain = pre_output.SalePrice.notnull().sum()\n",
    "        pre_train = pre_output[0:local_ntrain]\n",
    "        pre_test =pre_output[local_ntrain:].drop(\"SalePrice\",axis=1)\n",
    "\n",
    "        pre_train.to_hdf(filename,\"pre_train\")\n",
    "        pre_test.to_hdf(filename,\"pre_test\")\n",
    "        #print(\"\\n***Exported*** :{0}\".format(filename))\n",
    "        #print(\"\\ttrain set size :\\t\",local_ntrain)\n",
    "        #print(\"\\tpre_train shape:\\t\", pre_train.shape)\n",
    "        #print(\"\\tpre_test  shape:\\t\", pre_test.shape)\n",
    "        return pre_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:35:24.555854Z",
     "start_time": "2018-04-08T13:35:24.489195Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe_rmsetest(pre_combined):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    GLOBAL_SEED=42\n",
    "    NORMALIZE =False\n",
    "    target_col =\"SalePrice\"\n",
    "    nCV=5\n",
    "    ntrain = pre_combined[\"SalePrice\"].notnull().sum()\n",
    "    \n",
    "    X_train = pre_combined[:ntrain].drop([target_col,\"Id\"],axis=1)\n",
    "    X_test  = pre_combined[ntrain:].drop([target_col,\"Id\"],axis=1)\n",
    "    Y_train = pre_combined[:ntrain][target_col]\n",
    "    \n",
    "    \n",
    "    \n",
    "    from sklearn.pipeline import make_pipeline,Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler,Normalizer,RobustScaler\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score,train_test_split,KFold,cross_val_predict,StratifiedShuffleSplit\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.metrics import  make_scorer,mean_squared_error,r2_score\n",
    "    from sklearn.linear_model import Lasso,ElasticNet,Ridge,BayesianRidge,RANSACRegressor,HuberRegressor,LassoCV\n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "    from sklearn.svm import SVR,LinearSVR\n",
    "    from sklearn.ensemble import GradientBoostingRegressor,ExtraTreesRegressor,AdaBoostRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "    \n",
    "\n",
    "    LineRig =Ridge(random_state=GLOBAL_SEED,alpha=0.1,max_iter=5000)\n",
    "    LSVR =SVR(kernel=\"rbf\",C=1,epsilon=0.01,max_iter=5000)\n",
    "    LLasso = Lasso(random_state=GLOBAL_SEED,max_iter=5000,alpha=0.1)\n",
    "    LineEN = ElasticNet(random_state=GLOBAL_SEED,alpha=0.1,max_iter=5000)\n",
    "    \n",
    "    xgbreg = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=1000,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             seed =GLOBAL_SEED)\n",
    "    \n",
    "\n",
    "    LGB =LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                       learning_rate=0.05, n_estimators=720,\n",
    "                      bagging_fraction = 0.8,\n",
    "                       bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                       feature_fraction_seed=9, bagging_seed=9,\n",
    "                       min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,random_state=GLOBAL_SEED)\n",
    "    GBR = GradientBoostingRegressor(loss = 'huber',n_estimators=1000,learning_rate=0.005, \n",
    "                                    max_features='sqrt',min_samples_leaf=15,\n",
    "                                    min_samples_split=10,max_depth=4,\n",
    "                                    random_state=GLOBAL_SEED) # difficult to use for hyper tuning\n",
    "   \n",
    "    \n",
    "    estimators_list =[\n",
    "        LineRig,LLasso,LineEN,LSVR #,LGB,xgbreg\n",
    "                     ] \n",
    "    \n",
    "    for estimator in estimators_list :\n",
    "        \n",
    "        name = type(estimator).__name__\n",
    "        pipe = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            SelectFromModel(LassoCV(), threshold=1e-5),\n",
    "            estimator)\n",
    "                \n",
    "        np.random.seed(GLOBAL_SEED)\n",
    "        \n",
    "        cv_scores = cross_val_score(pipe,X_train,Y_train,cv=nCV,scoring =\"neg_mean_squared_error\" ) \n",
    "        \n",
    "        mean_score =np.sqrt( -cv_scores).mean()\n",
    "        \n",
    "        \n",
    "        print(\"{0:.4f} \\t\\t{1}\".format(mean_score,name))\n",
    "        \n",
    "    return pre_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:37:45.910133Z",
     "start_time": "2018-04-08T13:37:25.053868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** \n",
      "\n",
      "PIPE_start_fillna_ascat_drop4cols_outliers4k_extract_log_getdummies_drop_dummycols_rmsetest_export\n",
      "Int64Index([523, 1298], dtype='int64')\n",
      "0.1169 \t\tRidge\n",
      "0.2058 \t\tLasso\n",
      "0.1601 \t\tElasticNet\n",
      "0.1586 \t\tSVR\n",
      "********** \n",
      "\n",
      "PIPE_fillna_ascat_drop_cols_drop4cols_outliers4k_extract_log_getdummies_rmsetest_export\n",
      "Int64Index([523, 1298], dtype='int64')\n",
      "0.1132 \t\tRidge\n",
      "0.2058 \t\tLasso\n",
      "0.1602 \t\tElasticNet\n",
      "0.1546 \t\tSVR\n"
     ]
    }
   ],
   "source": [
    "pipe = [pipe_start,pipe_bypass,\\\n",
    "        pipe_fillna_ascat,pipe_drop_cols,\\\n",
    "        pipe_drop4cols,pipe_outliersdrop,\\\n",
    "        pipe_extract,pipe_log_getdummies, \\\n",
    "        pipe_rmsetest,pipe_bypass]\n",
    "\n",
    "pipe_outlier4k = [pipe_fillna_ascat,pipe_drop_cols,\\\n",
    "              pipe_drop4cols,pipe_outliers4k,\\\n",
    "              pipe_extract,pipe_bypass,\\\n",
    "              pipe_log_getdummies,pipe_bypass, \\\n",
    "              pipe_bypass,\n",
    "              pipe_rmsetest,pipe_export]\n",
    "\n",
    "pipe_1169 = [pipe_start,pipe_fillna_ascat,\n",
    "             pipe_drop4cols,pipe_outliers4k,\n",
    "            pipe_extract,pipe_bypass,\n",
    "             pipe_log_getdummies,pipe_drop_dummycols,\n",
    "            pipe_bypass,\n",
    "            pipe_rmsetest,pipe_export]\n",
    "\n",
    "\n",
    "#PIPE_fillna_ascat_drop4cols_outliersdrop_extract_log_getdummies_drop_dummycols_export_r2test_11-08-10_\n",
    "pipes = [pipe_1169,pipe_outlier4k   ]\n",
    "\n",
    "for i in range(len(pipes)):\n",
    "    print(\"*\"*10,\"\\n\")\n",
    "    pipe_output=pipes[i]\n",
    "    output_name =\"_\".join([x.__name__[5:] for x in pipe_output if x.__name__ is not \"pipe_bypass\"])\n",
    "    output_name = \"PIPE_\" +output_name\n",
    "    print(output_name)\n",
    "    tmp = (combined.pipe(pipe_output[0])\n",
    "             .pipe(pipe_output[1])\n",
    "             .pipe(pipe_output[2])\n",
    "             .pipe(pipe_output[3])\n",
    "             .pipe(pipe_output[4])\n",
    "             .pipe(pipe_output[5])          \n",
    "             .pipe(pipe_output[6])\n",
    "             .pipe(pipe_output[7])\n",
    "             .pipe(pipe_output[8])          \n",
    "             .pipe(pipe_output[9])\n",
    "            .pipe(pipe_output[10],output_name)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:38:30.665815Z",
     "start_time": "2018-04-08T13:38:30.647965Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:['./prepare/PIPE_start_fillna_ascat_drop4cols_outliers4k_extract_log_getdummies_drop_dummycols_rmsetest_export_04-08-13_37.h5', './prepare/PIPE_fillna_ascat_drop_cols_drop4cols_outliers4k_extract_log_getdummies_rmsetest_export_04-08-13_37.h5']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "handler = logging.FileHandler('hello.log')\n",
    "handler.setLevel(logging.INFO)\n",
    " \n",
    "# create a logging format\n",
    " \n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    " \n",
    "# add the handlers to the logger\n",
    " \n",
    "logger.addHandler(handler)\n",
    "GLOBAL_SEED=42\n",
    "GLOBAL_VERBOSE=2\n",
    "#GLOBAL_SEED=np.random.randint(100)\n",
    "print(GLOBAL_SEED)\n",
    "GLOBAL_TMP_FOLDER =\".\"\n",
    "SKIPMAP=True\n",
    "NORMALIZE =False\n",
    "import os\n",
    "h5files = []\n",
    "folders =[#\"./prepare/submitted & score =0.11699/\",\n",
    "          \"./prepare/\"]\n",
    "for folder in folders:\n",
    "    flist = os.listdir(folder)\n",
    "    files = [folder+x for x in flist if x.endswith(\".h5\")]\n",
    "    h5files.extend(files)\n",
    "logger.info(h5files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:38:49.375571Z",
     "start_time": "2018-04-08T13:38:49.342258Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_job(estimator,score=\"None\",verbose=0,dataset=\"\"):\n",
    "    from sklearn.externals import joblib\n",
    "    from datetime import datetime\n",
    "    import csv\n",
    "    \n",
    "    store_path=\"./models/\"\n",
    "    \n",
    "    savetime=datetime.now().strftime(\"%m%d_%H%M\")\n",
    "    \n",
    "    if estimator.__class__.__name__ == 'Pipeline':\n",
    "        model_name = 'Pipeline_' +estimator.named_steps[\"clf\"].__class__.__name__\n",
    "    else:\n",
    "        model_name = estimator.__class__.__name__\n",
    "    filename = store_path + \"HT_{0:.4f}_{1}_{2}.model\".format(score,model_name,savetime)\n",
    "    result = joblib.dump(estimator,filename)\n",
    "     \n",
    "    with open(\"tuned_log.csv\",\"a+\") as csvfile: \n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        #columns_name\n",
    "        #writer.writerow([\"index\",\"a_name\",\"b_name\"])\n",
    "        #writerows\n",
    "        writer.writerows([[datetime.now(),model_name,score,filename,dataset]])\n",
    "    if verbose!=0:\n",
    "        print(filename,\"\\t\", result)\n",
    "    return\n",
    "\n",
    "def load_job(filename):\n",
    "    from sklearn.externals import joblib\n",
    "    from datetime import datetime\n",
    "    \n",
    "    estimator = joblib.load(filename)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:39:07.002246Z",
     "start_time": "2018-04-08T13:39:06.396721Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer,RobustScaler\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV, RandomizedSearchCV,train_test_split,KFold,cross_val_predict,StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectFromModel,VarianceThreshold\n",
    "from sklearn.metrics import  make_scorer,mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.decomposition import PCA,FactorAnalysis,TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import Lasso,ElasticNet,LinearRegression,Ridge,BayesianRidge,LassoCV,RANSACRegressor,HuberRegressor\n",
    "\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR,NuSVR,LinearSVR,LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import GradientBoostingRegressor,ExtraTreesRegressor,AdaBoostRegressor,RandomForestRegressor,ExtraTreesClassifier\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:39:22.553188Z",
     "start_time": "2018-04-08T13:39:22.523150Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selector\n",
    "#sfm = SelectFromModel(ExtraTreesRegressor(random_state = GLOBAL_SEED))\n",
    "\n",
    "#line estimators\n",
    "#LineReg = LinearRegression(NORMALIZE)\n",
    "LineRig = Ridge(random_state=GLOBAL_SEED,alpha=0.001)\n",
    "LLasso = Lasso(random_state=GLOBAL_SEED,alpha =0.001)\n",
    "LineEN = ElasticNet(random_state=GLOBAL_SEED,alpha=0.001)\n",
    "LBayes = BayesianRidge()\n",
    "\n",
    "#gradient boost estimator\n",
    "#****** learning_rate ,n_estimators\n",
    "xgbreg = XGBRegressor(n_estimators=1000,learning_rate=0.05,\n",
    "                      subsample=0.5,\n",
    "                      #colsample_bytree=0.4603, gamma=0.0468, \n",
    "                      #max_depth=3, min_child_weight=1.7817, \n",
    "                      #reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                      # silent=1,\n",
    "                      nthread = -1,seed=GLOBAL_SEED)\n",
    "\n",
    "lgbm =LGBMRegressor(objective='regression',\n",
    "                    learning_rate=0.05, n_estimators=1000,\n",
    "                    subsample=0.5,\n",
    "                    #max_bin = 55, bagging_fraction = 0.8,\n",
    "                    #bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                    #feature_fraction_seed=9, bagging_seed=9,\n",
    "                    #min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,\n",
    "                    random_state=GLOBAL_SEED)\n",
    "\n",
    "GBR = GradientBoostingRegressor(loss = 'huber',n_estimators=2000,\n",
    "                                learning_rate=0.05, subsample=0.5,\n",
    "                               # max_features='sqrt',min_samples_leaf=15,\n",
    "                               # min_samples_split=10,max_depth=4,\n",
    "                                random_state=GLOBAL_SEED) # difficult to use for hyper tuning\n",
    " \n",
    "\n",
    "#Tree estimators (learning rate)\n",
    "ET= ExtraTreesRegressor( random_state=GLOBAL_SEED)\n",
    "RF = RandomForestRegressor(max_depth=30, n_estimators=500, max_features = 100, oob_score=True, n_jobs=-1, random_state=1234)\n",
    "#Kernel Ridge\n",
    "KRidge =KernelRidge(kernel =\"polynomial\",degree=2,coef0=4 )\n",
    "\n",
    "#SVM\n",
    "Lsvr = SVR(kernel=\"linear\",C=0.01,max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:39:34.901438Z",
     "start_time": "2018-04-08T13:39:34.876605Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Params_lasso ={\"Scaler\":[RobustScaler()],\n",
    "              \"selector__threshold\":np.logspace(-5,-4,3),\n",
    "    #\"Normer\":[None,Normalizer(norm='l2'),Normalizer(norm='l1')],\n",
    "    \"clf__alpha\":np.logspace(-5,-1,10),\n",
    "    #\"Sfm__n_components\":SVD_n_components,\n",
    "    #\"Sfm__threshold\":sfm_threshold,\n",
    "                      }\n",
    "Params_Ridge ={\"Scaler\":[None,RobustScaler()],\n",
    "               \"selector__threshold\":np.logspace(-5,-4,3),\n",
    "    #\"Normer\":[None,Normalizer(norm='l2'),Normalizer(norm='l1')],\n",
    "                \"clf__alpha\":np.logspace(-2,2,5),\n",
    "    #\"Sfm__n_components\":SVD_n_components,\n",
    "    #\"Sfm__threshold\":sfm_threshold,\n",
    "        }\n",
    "\n",
    "Params_ElasticNet={\"Scaler\":[RobustScaler()],\n",
    "                   \"selector__threshold\":np.logspace(-5,-4,3),\n",
    "                       # \"Normer\":[None,Normalizer(norm='l2'),Normalizer(norm='l1')],\n",
    "                       \"clf__alpha\":np.logspace(-5,-1,10),\n",
    "                            #\"Sfm__n_components\":SVD_n_components,\n",
    "                            #\"Sfm__threshold\":sfm_threshold,\n",
    "                           }\n",
    "Params_SVR={\"Scaler\":[RobustScaler()],\n",
    "             \"selector__threshold\":np.logspace(-5,-4,3),\n",
    "              \"clf__C\":np.logspace(-2,0,3),\n",
    "                     #\"clf__kernel\":[\"linear\"],\n",
    "               }\n",
    "\n",
    "Params_LGBMRegressor={\"Scaler\":[RobustScaler(),StandardScaler()],\n",
    "                       \"selector__threshold\":np.logspace(-5,-4,3),\n",
    "                      \"clf__n_estimators\":[500,1000],\n",
    "                       \"clf__learning_rate\":np.logspace(-2,-1,2), #\n",
    "                              # \"Normer\":[None,Normalizer(norm='l2'),Normalizer(norm='l1')],\n",
    "                               #\"Sfm__n_components\":SVD_n_components,\n",
    "                               #\"Sfm__threshold\":sfm_threshold,\n",
    "                              }\n",
    "\n",
    "Params_XGBRegressor={\"Scaler\":[StandardScaler(),RobustScaler()],\n",
    "                               \"selector__threshold\":np.logspace(-6,-4,3),\n",
    "                               \"clf__n_estimators\":[500,1000],\n",
    "                               \"clf__learning_rate\":[0.01,0.1],\n",
    "                               \"clf__reg_alpha\":np.logspace(-3,-1,3),\n",
    "                               \"clf__reg_lambda\":np.logspace(-2,0,3),\n",
    "                              }\n",
    "\n",
    "Params_GradientBoostingRegressor={\"Scaler\":[RobustScaler(),StandardScaler()],\n",
    "                                   \"selector__threshold\":np.logspace(-5,-4,3),\n",
    "                                   \"clf__n_estimators\":[500,1000],#\n",
    "                               \"clf__learning_rate\":np.logspace(-2,-1,2), #\n",
    "                                \"clf__max_depth\":[3,5,7],\n",
    "                              # \"Normer\":[None,Normalizer(norm='l2'),Normalizer(norm='l1')],\n",
    "                               #\"Sfm__n_components\":SVD_n_components,\n",
    "                               #\"Sfm__threshold\":sfm_threshold,\n",
    "                              }\n",
    "Params_groups ={\"Lasso\":Params_lasso,\n",
    "               \"Ridge\":Params_Ridge,\n",
    "               \"ElasticNet\":Params_ElasticNet,\n",
    "                \"SVR\":Params_SVR,\n",
    "                \"LGBMRegressor\":Params_LGBMRegressor,\n",
    "                \"XGBRegressor\":Params_XGBRegressor,\n",
    "                \"GradientBoostingRegressor\":Params_GradientBoostingRegressor,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:39:44.938229Z",
     "start_time": "2018-04-08T13:39:44.919437Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_clf_grids(estimators_list):\n",
    "    #clf_grids dictionary definition:\n",
    "    #Key : the estimator name. It is the type(estimator).__name__\n",
    "    #Value is a list [ x0,x1,x2,x3]\n",
    "    #value[0] is the estimator it self\n",
    "    #values[1] is the params_grid to be turned\n",
    "    #values[2] is the tuned estimator\n",
    "    #values[3] is the rmse of tuned estimator best test score\n",
    "    #values[4] is reserved, the predicted result\n",
    "    \n",
    "    grids={}\n",
    "    for x in estimators_list:\n",
    "        name = (type(x).__name__)\n",
    "        grids[name]=[x,{},None,None,None]    \n",
    "        grids[name][1] = Params_groups[name]\n",
    "    return grids\n",
    "\n",
    "full_estimators_list =[LineRig,LLasso,LineEN,Lsvr,lgbm,xgbreg,GBR] \n",
    "clf_grids = make_clf_grids(full_estimators_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:40:24.753328Z",
     "start_time": "2018-04-08T13:40:04.971964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=42, solver='auto', tol=0.001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ***** ./prepare/PIPE_start_fillna_ascat_drop4cols_outliers4k_extract_log_getdummies_drop_dummycols_rmsetest_export_04-08-13_37.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=42,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1142 \t\tRidge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=42, selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1133 \t\tLasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:SVR(C=0.01, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1119 \t\tElasticNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:LGBMRegressor(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.05,\n",
      "       max_bin=255, max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
      "       min_split_gain=0, n_estimators=1000, nthread=-1, num_leaves=31,\n",
      "       objective='regression', random_state=42, reg_alpha=0, reg_lambda=0,\n",
      "       seed=0, silent=True, subsample=0.5, subsample_for_bin=50000,\n",
      "       subsample_freq=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1135 \t\tSVR\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "b'Unknown parameter: random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-eea2f14e0e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtop_base_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time top_base_filename = baseline()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-eea2f14e0e06>\u001b[0m in \u001b[0;36mbaseline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mbase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtop_base_score\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtop_base_score\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbase_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mtop_base_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-eea2f14e0e06>\u001b[0m in \u001b[0;36mbaseline_cols\u001b[0;34m(filename, nCV)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGLOBAL_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnCV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcachedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             return_times=True)\n\u001b[0;32m--> 195\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    487\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    389\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m\"\"\"construct booster\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;34m\"\"\"construct booster object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1213\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, max_bin, reference, weight, group, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init_from_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: b'Unknown parameter: random_state'"
     ]
    }
   ],
   "source": [
    "def baseline_cols(filename =\"\",nCV=5):\n",
    "    from tempfile import mkdtemp\n",
    "    from shutil import rmtree\n",
    "    cachedir = mkdtemp(dir=GLOBAL_TMP_FOLDER)\n",
    "\n",
    "    if filename ==\"\":\n",
    "        print(\"Expect the prepared train/test hdf format filename as input parameter\")\n",
    "        return\n",
    "    \n",
    "    train = pd.read_hdf(filename,\"pre_train\")\n",
    "    test  = pd.read_hdf(filename,\"pre_test\")\n",
    "    \n",
    "    X_train = train.drop([\"Id\",\"SalePrice\"],axis=1)\n",
    "    \n",
    "    Y_train =train.SalePrice\n",
    "    \n",
    "    X_test = test.drop([\"Id\"],axis=1)\n",
    "    ID_test = test.Id\n",
    "\n",
    "    result = []\n",
    "   \n",
    "  \n",
    "    all_means =[]\n",
    "    for i in full_estimators_list:\n",
    "        logger.info(i)\n",
    "        cachedir = mkdtemp(dir=GLOBAL_TMP_FOLDER)\n",
    "        estimator = i\n",
    "        name = type(estimator).__name__\n",
    "        #print(name)\n",
    "        pipe = Pipeline([(\"Scaler\",RobustScaler()),\n",
    "                         (\"selector\",SelectFromModel(LassoCV(cv=5),threshold=1e-5)),\n",
    "                         (\"clf\",estimator)],memory=None)\n",
    "        np.random.seed(GLOBAL_SEED)\n",
    "        \n",
    "        cv_scores = cross_val_score(pipe,X_train,Y_train,cv=nCV,scoring =\"neg_mean_squared_error\" ) \n",
    "        \n",
    "        rmtree(cachedir)\n",
    "        \n",
    "        mean_score =np.sqrt( -cv_scores).mean()\n",
    "        save_job(estimator,mean_score,dataset=filename)\n",
    "        \n",
    "        print(\"{0:.4f} \\t\\t{1}\".format(mean_score,name))\n",
    "        all_means.append(mean_score)\n",
    "        \n",
    "                                       \n",
    "    return np.mean(all_means)\n",
    "        \n",
    "def baseline():\n",
    "    top_base_score =None\n",
    "    top_base_filename=\"\"\n",
    "\n",
    "\n",
    "    for file in h5files:\n",
    "        if os.path.isfile(file):\n",
    "            print(\"\\n\\n\",\"*\"*5,file)\n",
    "            base_score = baseline_cols(file)\n",
    "            if top_base_score ==None or top_base_score>base_score:\n",
    "                top_base_score = base_score\n",
    "                top_base_filename =file\n",
    "    print(\"*\"*20)\n",
    "    print(\"the top baseline score(averge) :=\",top_base_score)\n",
    "    print(\"the top baseline used filename :=\",top_base_filename)\n",
    "    return top_base_filename\n",
    "    \n",
    "%time top_base_filename = baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:41:00.631862Z",
     "start_time": "2018-04-08T13:41:00.532135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Tuning_clf(name,search_type=\"\",verbose=0, nCV=5,filename =\"\"):\n",
    "    from tempfile import mkdtemp\n",
    "    from shutil import rmtree\n",
    "    \n",
    "    if filename ==\"\":\n",
    "        print(\"Expect the prepared train/test hdf format filename as input parameter\")\n",
    "        return\n",
    "    \n",
    "    train = pd.read_hdf(filename,\"pre_train\")\n",
    "    test  = pd.read_hdf(filename,\"pre_test\")\n",
    "    \n",
    "    X_train = train.drop([\"Id\",\"SalePrice\"],axis=1)\n",
    "    Y_train =train.SalePrice\n",
    "    # the log transfer has been done in preprocess stage.In order to keep compatible, keep the log_Y_train name\n",
    "  \n",
    "    X_test = test.drop([\"Id\"],axis=1)\n",
    "    ID_test = test.Id\n",
    "\n",
    "\n",
    "    result=[]\n",
    "    estimator = clf_grids[name][0]\n",
    "    estimator_params=clf_grids[name][1]\n",
    "    cachedir = mkdtemp(dir=GLOBAL_TMP_FOLDER)\n",
    "    pipe = Pipeline([(\"Scaler\",None),\n",
    "                    # (\"Normer\",None),\n",
    "                     (\"selector\",SelectFromModel(LassoCV(cv=10),threshold=1e-5)),\n",
    "                     (\"clf\",estimator)],memory=cachedir) \n",
    "    \n",
    "    t0=time()\n",
    "    \n",
    "    def params_size(estimator_params):\n",
    "        size = 0\n",
    "        nlen=0\n",
    "        \n",
    "        for k,v in estimator_params.items():\n",
    "            size +=len(v)\n",
    "        return size\n",
    "        \n",
    "        \n",
    "    if search_type ==\"Grid\" or params_size(estimator_params)<=10:\n",
    "        rsearch = GridSearchCV(pipe, param_grid=estimator_params,scoring ='neg_mean_squared_error',verbose=verbose,cv=nCV,refit =True)\n",
    "    else:\n",
    "        rsearch = RandomizedSearchCV(pipe, param_distributions=estimator_params,\n",
    "                                     scoring ='neg_mean_squared_error',verbose=verbose,\n",
    "                                     cv=nCV,random_state=GLOBAL_SEED,refit =True)\n",
    "    \n",
    "    rsearch.fit(X_train,Y_train)\n",
    "    rmtree(cachedir)\n",
    "    #nfeatures =rsearch.best_estimator_.steps[1][1].get_support().sum()\n",
    "    nfeatures =X_train.shape[1]\n",
    "    id_best = rsearch.best_index_\n",
    "    \n",
    "    mean = rsearch.cv_results_[\"mean_test_score\"][id_best]\n",
    "    std  = rsearch.cv_results_[\"std_test_score\"][id_best]\n",
    "    rmse_std = std # The std was just reference as it is std mean.so skip sqrt process\n",
    "    rmse_mean = np.sqrt(-mean)\n",
    "    rmse_zp2 =np.sqrt(-(mean)+2*std)\n",
    "    rmse_zm2 =np.sqrt(-(mean)-2*std)\n",
    "    rmse_mean, rmse_zp2,rmse_zm2\n",
    "    \n",
    "    t1=time()\n",
    "    #print(\"********* {1} \\t******** completed in: {0:2f} seconds\".format(t1-t0,name))\n",
    "    #print(\"*\"*10)\n",
    "   \n",
    "    result.append([filename,\"Tuned\",name,rmse_mean,rmse_std,rmse_zp2,rmse_zm2,nfeatures,nCV,str(rsearch.best_params_)[:1000]])\n",
    "    logtime=datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "    print(logtime,\"\\t\",name,\"\\t\",\"\\t{0:.6f}\\t{1:0.6f}\"\"\\t{2:.6f}\\t{3:0.6f}\".format(rmse_mean,rmse_std,rmse_zp2,rmse_zm2,),\"\\n\\t\",(rsearch.best_params_))\n",
    "    #param_plot(rsearch.cv_results_,name)\n",
    "    #learning_curve_plot(rsearch.cv_results_,name)\n",
    "     \n",
    "    #result_df = pd.DataFrame(result,columns=[\"Filename\",\"HyperTuned\",\"estimator\", \"mean\",\"std\",\"ZP2\",\"ZM2\",\"Nfeatures\",\"nCV\",\"pipe_info\"],index=[logtime for i in range(len(clf_grids))])\n",
    "    #result_df.to_hdf(\"./result_log_1101_v0.h5\", \"result\",append=True,format=\"t\",min_itemsize = {\"Filename\":150, \"pipe_info\" : 1000 })\n",
    "    \n",
    "    return rsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:41:15.746878Z",
     "start_time": "2018-04-08T13:41:15.722217Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_base_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-f38b507865e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimators_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_grids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtop_base_filename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"not existed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_base_filename' is not defined"
     ]
    }
   ],
   "source": [
    "estimators_names = [x for x in clf_grids.keys()]\n",
    "\n",
    "for filename in [top_base_filename]:\n",
    "    if not os.path.isfile(filename):\n",
    "        print(filename, \"not existed\")\n",
    "    else:\n",
    "        print(\"\\n\\n\",\"*\"*5,filename)\n",
    "       \n",
    "        for name in  estimators_names:\n",
    "            #print(filename)\n",
    "            #print(clf_grids[name][1])\n",
    "            tuned_clf=Tuning_clf(name,verbose=0,nCV=10,filename = filename)\n",
    "            best_estimator = tuned_clf.best_estimator_\n",
    "\n",
    "            rmse = np.sqrt(-tuned_clf.best_score_ )\n",
    "            #Pred_Y=best_estimator.predict(X_test)\n",
    "            clf_grids[name][2]=best_estimator\n",
    "            clf_grids[name][3]=rmse\n",
    "            #clf_grids[name][4]=Pred_Y\n",
    "            save_job(best_estimator,rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:41:46.455372Z",
     "start_time": "2018-04-08T13:41:46.428385Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_base_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-0e4aaf3ebcab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtop_base_filename\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#use the top base score inputed file for ensembling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_base_filename' is not defined"
     ]
    }
   ],
   "source": [
    "def rmsle_cv(model,filename =top_base_filename ):\n",
    "    \n",
    "    #use the top base score inputed file for ensembling.\n",
    "    \n",
    "    n_folds=5\n",
    "    \n",
    "    train = pd.read_hdf(filename,\"pre_train\")\n",
    "    test  = pd.read_hdf(filename,\"pre_test\")\n",
    "    X_train = train.drop([\"Id\",\"SalePrice\"],axis=1)\n",
    "    Y_train = train.SalePrice\n",
    "    \n",
    "    kf = KFold(n_folds, shuffle=True, random_state=GLOBAL_SEED).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, Y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    save_job(model,rmse.mean(),top_base_filename)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:42:01.281226Z",
     "start_time": "2018-04-08T13:42:01.240552Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_base_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-42564982348b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpredict2csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_base_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_base_filename' is not defined"
     ]
    }
   ],
   "source": [
    "def predict2csv(model , filename=top_base_filename):\n",
    "    import os\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if not os.path.isfile(filename):\n",
    "        print(\"Expect filename(h5 format) as input for average tuning\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n\\n\",\"*\"*5,filename)\n",
    "    \n",
    "    train = pd.read_hdf(filename,\"pre_train\")\n",
    "    test  = pd.read_hdf(filename,\"pre_test\")\n",
    "    X_train = train.drop([\"Id\",\"SalePrice\"],axis=1)\n",
    "    Y_train =train.SalePrice\n",
    "    X_test =test.drop([\"Id\"],axis=1)\n",
    "    ID_test =test[\"Id\"]\n",
    "\n",
    "    pred_average = model.fit(X_train,Y_train).predict(X_test).tolist()\n",
    "    #pred_average = model.fit(X_train,Y_train).predict(X_test).tolist()\n",
    "\n",
    "\n",
    "    Y_pred = np.expm1(pred_average)\n",
    "    solution = pd.DataFrame()\n",
    "    solution[\"Id\"] = ID_test\n",
    "    solution[\"SalePrice\"] = Y_pred\n",
    "\n",
    "    predict_name = \"_stackaverage_\"\n",
    "    savetime=datetime.now().strftime(\"%m%d_%H%M\")\n",
    "    pre_process_name =re.search(\"PIPE_(.*).h5\",filename).group(1)\n",
    "    output_filename = \"./submit/\"+pre_process_name+predict_name+savetime+\".csv\"\n",
    "\n",
    "    solution.to_csv(output_filename , index = False)\n",
    "    print(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:42:18.787600Z",
     "start_time": "2018-04-08T13:42:18.776748Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:42:29.937382Z",
     "start_time": "2018-04-08T13:42:29.909635Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict2csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-a7cff36537e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maveraged_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAveragingModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf_grids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_grids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredict2csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maveraged_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_base_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maveraged_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict2csv' is not defined"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = [clf_grids[x][2] for x in clf_grids.keys()])\n",
    "\n",
    "predict2csv(averaged_models,top_base_filename)\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:42:39.863305Z",
     "start_time": "2018-04-08T13:42:39.848422Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmsle_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-2f8658f93356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maveraged_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rmsle_cv' is not defined"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(averaged_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:42:57.841738Z",
     "start_time": "2018-04-08T13:42:57.805694Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        #print(self.meta_model)\n",
    "        X=X.values\n",
    "        y=y.values\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=GLOBAL_SEED)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            #print(i,type(model).__name__)\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        \n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        \n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:43:26.407218Z",
     "start_time": "2018-04-08T13:43:26.390880Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict2csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-e2e6bae54b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict2csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_grids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Lasso\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_base_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msavetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m%d_%H%M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_averaged_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Stacked_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maveraged_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Average_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict2csv' is not defined"
     ]
    }
   ],
   "source": [
    "predict2csv(clf_grids[\"Lasso\"][2],top_base_filename)\n",
    "from sklearn.externals import joblib\n",
    "savetime=datetime.now().strftime(\"%m%d_%H%M\")\n",
    "joblib.dump(stacked_averaged_models,\"Stacked_\"+savetime)\n",
    "joblib.dump(averaged_models,\"Average_\"+savetime)\n",
    "print(filename,\"\\t\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:43:44.297591Z",
     "start_time": "2018-04-08T13:43:44.257509Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stacked_averaged_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-9e5495e515ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m final_estimators ={\"estimator\":[stacked_averaged_models ,clf_grids[\"LGBMRegressor\"][2],clf_grids[\"XGBRegressor\"][2]],\n\u001b[0m\u001b[1;32m     15\u001b[0m                    \u001b[0;34m\"names\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Stacked\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"LGBMRegressor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"XGBRegressor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                    \u001b[0;34m\"train_pred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stacked_averaged_models' is not defined"
     ]
    }
   ],
   "source": [
    "def rmsle(estimator):\n",
    "    train = pd.read_hdf(filename,\"pre_train\")\n",
    "    test  = pd.read_hdf(filename,\"pre_test\")\n",
    "    X_train = train.drop([\"Id\",\"SalePrice\"],axis=1)\n",
    "    X_test = test.drop([\"Id\"],axis=1)\n",
    "    Y_train =train.SalePrice\n",
    "    estimator.fit(X_train,Y_train)\n",
    "    train_pred = estimator.predict(X_train)\n",
    "    test_pred = estimator.predict(X_test)\n",
    "    score = np.sqrt(mean_squared_error(Y_train, train_pred))\n",
    "    print(\"final score = {0}\".format(score))\n",
    "    return train_pred,test_pred\n",
    "    \n",
    "final_estimators ={\"estimator\":[stacked_averaged_models ,clf_grids[\"LGBMRegressor\"][2],clf_grids[\"XGBRegressor\"][2]],\n",
    "                   \"names\":[\"Stacked\",\"LGBMRegressor\",\"XGBRegressor\"],\n",
    "                   \"train_pred\":[None,None,None],\n",
    "                   \"test_pred\":[None,None,None],\n",
    "                  }\n",
    "\n",
    "for i in range(3):\n",
    "    name = final_estimators[\"names\"][i]\n",
    "    estimator = final_estimators[\"estimator\"][i]\n",
    "   \n",
    "    train_pred,test_pred = rmsle(estimator)\n",
    "    final_estimators[\"train_pred\"][i] = train_pred\n",
    "    final_estimators[\"test_pred\"][i] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
